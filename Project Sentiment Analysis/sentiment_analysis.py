# -*- coding: utf-8 -*-
"""Sentiment analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vA5Om9uEhcHBteK4AznYCDf6NBBZHIPj
"""

import pandas as pd

# Load dataset, handling potential errors with 'on_bad_lines' and 'engine' parameters
df = pd.read_csv('C:\Users\Admin\AIO-189-phatpham-1\Project Sentiment Analysis\IMDB-Dataset.csv', on_bad_lines='skip', engine='python')

# Remove duplicate rows
df = df.drop_duplicates()

## cleaning The Data ##
import re
import string
import nltk
from bs4 import BeautifulSoup
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import contractions

# Downloading NLTK resources
nltk.download('stopwords')
nltk.download('wordnet')

stop = set(stopwords.words('english'))
wl = WordNetLemmatizer()

# Expand contractions
def expand_contractions(text):
    return contractions.fix(text)

# Function to clean data
def preprocess_text(text):
    # Removing html tags
    soup = BeautifulSoup(text, "html.parser")
    text = soup.get_text()

    # Expanding chatwords and contracts
    text = expand_contractions(text)

    # Removing emojis, punctuations, making text lowercase
    emoji_clean = re.compile("["u"\U0001F600-\U0001F64F"u"\U0001F300-\U0001F5FF"u"\U0001F680-\U0001F6FF"u"\U0001F1E0-\U0001F1FF""]+", flags=re.UNICODE)
    text = emoji_clean.sub(r'', text)
    text = re.sub(r'\.(?=\S)', '. ', text)  # Add space after full stop
    text = re.sub(r'http\S+', '', text)  # Remove URLs

    text = "".join([char.lower() for char in text if char not in string.punctuation])  # Remove punctuations
    text = " ".join([wl.lemmatize(word) for word in text.split() if word not in stop and word.isalpha()])  # Lemmatize

    return text

# Apply the cleaning function to the review column
df['review'] = df['review'].apply(preprocess_text)

## Data Analysis ##
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Frequencies of sentiment labels
freq_pos = len(df[df['sentiment'] == 'positive'])
freq_neg = len(df[df['sentiment'] == 'negative'])
data = [freq_pos, freq_neg]
labels = ['Positive', 'Negative']

# Pie chart
def func(pct, allvalues):
    absolute = int(pct / 100. * np.sum(allvalues))
    return "{:.1f}%\n({:d})".format(pct, absolute)

plt.pie(data, autopct=lambda pct: func(pct, data), explode=[0.0025, 0.0025], pctdistance=0.5)
plt.legend(labels, loc="best")
plt.show()

# Distribution of words per review
df_temp = df.copy()
df_temp['word_count'] = df['review'].apply(lambda x: len(x.split()))

sns.displot(data=df_temp[df_temp['sentiment'] == 'positive'], x="word_count", kde=True)
plt.title("Words in Positive Reviews")
plt.show()

sns.displot(data=df_temp[df_temp['sentiment'] == 'negative'], x="word_count", kde=True, color='red')
plt.title("Words in Negative Reviews")
plt.show()

!pip install contractions

##Train-Test Split##
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Encode labels
label_encoder = LabelEncoder()
y_data = label_encoder.fit_transform(df['sentiment'])

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(df['review'], y_data, test_size=0.2, random_state=42)

##Text Representation##
tfidf_vectorizer = TfidfVectorizer(max_features=10000)
x_train_encoded = tfidf_vectorizer.fit_transform(x_train)
x_test_encoded = tfidf_vectorizer.transform(x_test)

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Decision Tree
dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_classifier.fit(x_train_encoded, y_train)
y_pred_dt = dt_classifier.predict(x_test_encoded)
print(f"Decision Tree Accuracy: {accuracy_score(y_test, y_pred_dt)}")

# Random Forest
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(x_train_encoded, y_train)
y_pred_rf = rf_classifier.predict(x_test_encoded)
print(f"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf)}")